version: '3.6'

# Define named volumes for persistent data
volumes:
  apache-airflow_data:
    driver: local
  postgres_data:
    driver: local
  pgadmin_data:
    driver: local
  mongo_data:
    driver: local

# Define a custom network for services to communicate
networks:
  airflow_network:

services:

  # MongoDB container for Apache Airflow
  mongo:
    container_name: airflow_mongo
    image: mongo
    env_file:
      - .env
    ports:
      - "27017:27017"
    environment:
      - MONGO_INITDB_ROOT_USERNAME=${MONGO_ROOT_USER}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_ROOT_PASSWORD}
      - MONGO_INITDB_DATABASE=${MONGO_DB}
    networks:
      - airflow_network

  # Web-based MongoDB admin interface, written with Node.js and express
  mongo-express:
    image: mongo-express
    container_name: airflow_mongo_express
    restart: on-failure
    env_file:
      - .env
    environment:
      - ME_CONFIG_MONGODB_SERVER=airflow_mongo
      - ME_CONFIG_MONGODB_PORT=27017
      - ME_CONFIG_MONGODB_ENABLE_ADMIN=true
      - ME_CONFIG_MONGODB_AUTH_DATABASE=admin
      - ME_CONFIG_MONGODB_ADMINUSERNAME=${MONGO_ROOT_USER}
      - ME_CONFIG_MONGODB_ADMINPASSWORD=${MONGO_ROOT_PASSWORD}
      - ME_CONFIG_BASICAUTH_USERNAME=${MONGOEXPRESS_LOGIN}
      - ME_CONFIG_BASICAUTH_PASSWORD=${MONGOEXPRESS_PASSWORD}
    depends_on:
      - mongo
    ports:
      - "8087:8081"
    networks:
      - airflow_network

  # Redis container for Apache Airflow's message broker
  redis:
    image: 'redis:5.0.5'
    container_name: airflow_broker
    restart: always
    networks:
      - airflow_network
    
  # PostgreSQL database container for Apache Airflow
  postgres:
    image: postgres:13
    container_name: airflow_db
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    env_file:
      - .env
    networks:
      - airflow_network

  # pgAdmin container for managing the PostgreSQL database
  pgadmin:
    image: dpage/pgadmin4
    container_name: airflow_db_ui
    restart: always
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
      PGADMIN_LISTEN_PORT: ${PGADMIN_LISTEN_PORT}
    env_file:
      - .env
    ports:
      - 8085:80
    volumes:
      - ./pgadmin_data:/var/lib/pgadmin
    networks:
      - airflow_network

  # Apache Airflow webserver container
  webserver:
    image: ssanchez11/lyric_wave_apache_airflow:0.0.1
    container_name: airflow_webserver
    restart: always
    env_file:
      - .env
    depends_on:
      - postgres
      - redis
    environment:
      LOAD_EX: ${LOAD_EX}
      FERNET_KEY: ${FERNET_KEY}
      EXECUTOR: ${EXECUTOR}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: ${POSTGRES_HOST}
      REDIS_HOST: ${REDIS_HOST}
    volumes:
      - ./airflow/dags:/usr/local/airflow/dags
      - ./airflow/packages:/usr/local/airflow/packages
    ports:
      - "8080:8080"
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3
    networks:
      - airflow_network

  # Flower is a web-based tool for monitoring and administrating Celery clusters.
  flower:
    image: ssanchez11/lyric_wave_apache_airflow:0.0.1
    container_name: airflow_flower
    restart: always
    env_file:
      - .env
    depends_on:
      - redis
    environment:
      EXECUTOR: ${EXECUTOR}
    ports:
      - "8081:5555"
      - "8082:8080"
      - "8083:8793"
    command: flower
    networks:
      - airflow_network

  # Apache Airflow scheduler container
  scheduler:
    image: ssanchez11/lyric_wave_apache_airflow:0.0.1
    container_name: airflow_scheduler
    restart: always
    env_file:
      - .env
    depends_on:
      - webserver
    volumes:
      - ./airflow/dags:/usr/local/airflow/dags
      - ./airflow/packages:/usr/local/airflow/packages
    environment:
      LOAD_EX: ${LOAD_EX}
      FERNET_KEY: ${FERNET_KEY}
      EXECUTOR: ${EXECUTOR}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: ${POSTGRES_HOST}
      REDIS_HOST: ${REDIS_HOST}
    ports:
      - "8084:8080"
    command: scheduler
    networks:
      - airflow_network

  # Apache Airflow worker containers
  worker:
    image: ssanchez11/lyric_wave_apache_airflow:0.0.1
    container_name: airflow_worker_1
    restart: always
    env_file:
      - .env
    depends_on:
      - scheduler
    volumes:
      - ./airflow/dags:/usr/local/airflow/dags
      - ./airflow/packages:/usr/local/airflow/packages
      - ./magentadata:${MODEL_OUTPUT_DIR}
    environment:
      FERNET_KEY: ${FERNET_KEY}
      EXECUTOR: ${EXECUTOR}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: ${POSTGRES_HOST}
      REDIS_HOST: ${REDIS_HOST}
    command: worker
    networks:
      - airflow_network


  api_service_1:
    image: ssanchez11/lyric_wave_api:0.0.1
    container_name: api_service_1
    restart: always
    env_file:
      - .env
    ports:
      - "8086:5000"
    networks:
      - airflow_network